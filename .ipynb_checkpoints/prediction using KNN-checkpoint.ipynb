{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the distance between feature vectors and find the neighbours\n",
    "def findNeighbour(trainSet , instance , k):\n",
    "    #gets the distance between the instance and all the points in the trainset\n",
    "    dist = []\n",
    "    for x in range (len(trainSet)):\n",
    "        tempDist = distance(trainSet[x] , instance , k) + distance(instance , trainSet[x] , k)\n",
    "        dist.append((trainSet[x][2] , tempDist))\n",
    "    \n",
    "    #then we sort distances\n",
    "    dist.sort(key = operator.itemgetter(1))\n",
    "    \n",
    "    #now we get the nearest k neighbours\n",
    "    neighbours = []\n",
    "    for x in range(k):\n",
    "        neighbours.append(dist[x][0])\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the class of the neighbours\n",
    "def neighbourClass(neighbours):\n",
    "    classVote = {}\n",
    "    \n",
    "    for x in range(len(neighbours)):\n",
    "        response = neighbours[x]\n",
    "        if response in classVote:\n",
    "            classVote[response] += 1\n",
    "        else:\n",
    "            classVote[response] = 1\n",
    "        \n",
    "    sorter = sorted(classVote.items() , key = operator.itemgetter(1) , reverse = True)\n",
    "    \n",
    "    return sorter[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to evaluate the model\n",
    "def accuracy(testSet , prediction):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "            \n",
    "    return (1.0 * correct) / len(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./music_data_set/Data/genres_original/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"my.dat\" , \"wb\")\n",
    "\n",
    "i = 0;\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    i += 1\n",
    "    if i == 11:\n",
    "        break\n",
    "    for file in os.listdir(directory+folder):        \n",
    "        try:\n",
    "            (rate, sig) = wav.read(directory+folder+\"/\"+file)\n",
    "            mfcc_feat = mfcc(sig, rate, winlen=0.020, appendEnergy=False)\n",
    "            covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "            mean_matrix = mfcc_feat.mean(0)\n",
    "            feature = (mean_matrix, covariance, i)\n",
    "            pickle.dump(feature, f)\n",
    "        except Exception as e:\n",
    "            print('Got an exception: ', e, ' in folder: ', folder, ' filename: ', file)        \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets respectively\n",
    "dataset = []\n",
    "\n",
    "def loadData(filename, split, trainSet, testSet):\n",
    "    with open('my.dat', 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break\n",
    "    for x in range(len(dataset)):\n",
    "        if random.random() < split:\n",
    "            trainSet.append(dataset[x])\n",
    "        else:\n",
    "            testSet.append(dataset[x])\n",
    "trainingSet = []\n",
    "testingSet = []\n",
    "loadData('my.dat', 0.66, trainingSet, testingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(instance1 , instance2 , k ):\n",
    "    distance =0 \n",
    "    mm1 = instance1[0] \n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1)) \n",
    "    distance+=(np.dot(np.dot((mm2-mm1).transpose() , np.linalg.inv(cm2)) , mm2-mm1 )) \n",
    "    distance+= np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance-= k\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691358024691358\n"
     ]
    }
   ],
   "source": [
    "# making predictions using KNN\n",
    "leng = len(testingSet)\n",
    "predictions = []\n",
    "for x in range(leng):\n",
    "    predictions.append(neighbourClass(findNeighbour(trainingSet, testingSet[x], 5)))\n",
    "\n",
    "accuracy1 = accuracy(testingSet, predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ac = accuracy_score(y_test , y_pred_rf)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the code with external samples\n",
    "\n",
    "test_dir = \"./music_data_set/Test/\"\n",
    "\n",
    "#hiphop\n",
    "# test_file = test_dir + \"test6.wav\"\n",
    "\n",
    "#blues\n",
    "# test_file = test_dir + \"test4.wav\"\n",
    "\n",
    "#pop\n",
    "# test_file = test_dir + \"test8.wav\"\n",
    "\n",
    "#rock\n",
    "# test_file = test_dir + \"test10.wav\"\n",
    "\n",
    "#jazz\n",
    "# test_file = test_dir + \"test7.wav\"\n",
    "\n",
    "#reggae\n",
    "# test_file = test_dir + \"test9.wav\"\n",
    "\n",
    "#metal\n",
    "# test_file = test_dir + \"test2.wav\"\n",
    "\n",
    "#country\n",
    "# test_file = test_dir + \"test.wav\"\n",
    "\n",
    "#disco\n",
    "# test_file = test_dir + \"test5.wav\"\n",
    "\n",
    "#classical\n",
    "# test_file = test_dir + \"test3.wav\"\n",
    "\n",
    "test_file = test_dir + \"unknown11.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-180-aa6969f48d34>:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  (rate, sig) = wav.read(test_file)\n"
     ]
    }
   ],
   "source": [
    "(rate, sig) = wav.read(test_file)\n",
    "mfcc_feat = mfcc(sig, rate, winlen=0.020, appendEnergy=False)\n",
    "covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "mean_matrix = mfcc_feat.mean(0)\n",
    "feature = (mean_matrix, covariance, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {1: 'HipHop',\n",
       "             2: 'Blues',\n",
       "             3: 'Pop',\n",
       "             4: 'Rock',\n",
       "             5: 'Jazz',\n",
       "             6: 'Reggae',\n",
       "             7: 'Metal',\n",
       "             8: 'Country',\n",
       "             9: 'Disco',\n",
       "             10: 'Classical'})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(int)\n",
    "\n",
    "results[1] = \"HipHop\"\n",
    "results[2] = \"Blues\"\n",
    "results[3] = \"Pop\"\n",
    "results[4] = \"Rock\"\n",
    "results[5] = \"Jazz\"\n",
    "results[6] = \"Reggae\"\n",
    "results[7] = \"Metal\"\n",
    "results[8] = \"Country\"\n",
    "results[9] = \"Disco\"\n",
    "results[10] = \"Classical\"\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop\n"
     ]
    }
   ],
   "source": [
    "pred = neighbourClass(findNeighbour(dataset, feature, 4))\n",
    "print(results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
